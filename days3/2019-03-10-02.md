
[CodeOnWeb : 머신러닝 초보를 위한 MNIST](https://codeonweb.com/entry/12045839-0aa9-4bad-8c7e-336b89401e10) 
- 위의 내용을 보며 실습

#### xnview 
> Raw inmage 확인

#### xnview 설치
>xnview.com -> For Desktops -> Viewr & organizer -> XnView -> Minimal -> [XnView Min.Zip](https://www.xnview.com/en/xnview/#downloads)


#### HxD 
> Raw image 코드확인
#### hexa editor 설치
>mh-nexus.de/en/hxd/ -> download page -> korean -> [Download per HTTPS](https://mh-nexus.de/en/downloads.php?product=HxD20)

----

```손글씨인식(회귀분석)
픽셀 화면을 이차원배열로 설정해두고 검정색의 자주 겹치는 부분을 체크하여 글자로 인식 
```

```One hot encoding
해당 픽셀은 one hot endcoding 데이터 형태의 무엇이다...?????
```

----
#### 실습
> jupyterLab 이용 : Mnist_tensor.ipnb 생성

#### 텐서플로우 Mnist 초급 자료를 Tenserflow를 활용하여 손글씨 인식 모델 생성
```python
#실행 : shift + enter
#실행 후 새로운 줄 생성 : alt + enter 

import tensorflow as tf
import Matlotlib.pyplot as plt
from tensorflow.examples.tutorials.mnist import input_data


#데이터 불러오기
# 윈도우에서는 드라이브명을 작성. one-hot encoding 형식으로 받아온다.
mnitst=input_data.read_data_sets('c:/MNIST/', one_hot=True)  
# 위의 경로에 t10k/...gz->테스트용으로 사용
print("train_data : ", mnist.train.images.shape)
print("train_label : ", mnist.train.labels.shape)

#결과
>train_data : (55000, 784)
>train_label : (55000, 10)

```

```python
#plt.imgshow(mnist.train.image[0])
data1=mnist.train.images[0]
imgdata=data1.reshape([28,28])
plt.imshow(imgdata)
print(mnist.train.labels[0])
```

#### 텐서플로우 시작
[머신러닝 초보를 위한 MNIST](https://codeonweb.com/entry/12045839-0aa9-4bad-8c7e-336b89401e10)
- 1.변수 지정
```python
# float32형태로 784개의 데이터가 (?)개 들어온다.

# xdata = 55000개의 train 데이터 중에서 784열의 데이터 n개를 받을 준비. 
# ydata = train 데이터 중 label data 55000개 중에서 10열의 데이터 n개를 받은 준비.
xdata = tf.placeholder(tf.float32, [None, 784]) 
ydata = tf.placeholder(tf.float32, [None,10])
```
- 2.Variable 지정
```python
w=tf.Variable(tf.zeros[784,10])
b=tf.Variable(tf.zeros[784,10])
```
- 3.모델지정
```python
y = tf.matmul(xdata,W)+b
y_= tf.nn.softmax(y)
```

- 4.손실 지정 
    - 크로스 엔트로피 : 분류 모델에서의 손실은 크로스 엔트로피 함수를 사용 (확률 추정의 한 방법)
```python
info_ydata * rf.log(y)
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
```


```python
lr=0.1 #learning_rate
optimizer=tf.train.GradientDescentOptimizer(lr)
train_step=optimizer.minimize(cross_entropy)

```

- 세션 초기화
```python
init = tf.global_variables_initializer()
sess = rf.Session()
sess.run(init)
```

- 트레이닝
```python
    for step in range(10) :
    batch_xs,batch_ys=mnist.train.next_batch(100)
    feed_dict={xdata:batch_xs,ydata:batch_ys}
    sess.run(train_step, feed_dict)
```
- 평가하기
```python
prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
acc = tf.reduce

```



>[솔라리스의 인공지능 연구실](http://solarisailab.com/)



